{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762aaf9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccb2b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from data_preprocessing import load_and_clean, feature_engineer, split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "175895d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing\n",
    "numeric_features = ['age', 'fnlwgt', 'educational-num', 'hours-per-week']\n",
    "categorical_features = [\n",
    "    'workclass','education','marital-status','occupation','relationship',\n",
    "    'race','gender','native-country','age_bin'\n",
    "]\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cda655fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "model_candidates = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=500, random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and collect accuracies\n",
    "accuracies = {}\n",
    "best_acc = 0.0\n",
    "best_model = None\n",
    "best_name = None\n",
    "\n",
    "for name, clf in model_candidates.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('pre', preprocessor),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    accuracies[name] = acc\n",
    "    print(f\"{name} accuracy: {acc:.4f}\")\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = pipeline\n",
    "        best_name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dad73e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to evaluate\n",
    "model_candidates = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=500, random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "accuracies = {}\n",
    "best_acc = 0.0\n",
    "best_model = None\n",
    "best_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a067335e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (745014671.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m])for name, clf in model_candidates.items():\u001b[39m\n      ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each model\n",
    "for name, clf in model_candidates.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('pre', preprocessor),\n",
    "        ('clf', clf)\n",
    "    ])for name, clf in model_candidates.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('pre', preprocessor),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    accuracies[name] = acc\n",
    "    print(f\"{name} accuracy: {acc:.4f}\")\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = pipeline\n",
    "        best_name = name\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"{name} accuracy: {acc:.4f}\")\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = pipeline\n",
    "        best_name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83eb5e0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      2\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m plt.bar(\u001b[43maccuracies\u001b[49m.keys(), accuracies.values())\n\u001b[32m      4\u001b[39m plt.ylabel(\u001b[33m'\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mModel Comparison: Accuracy Scores\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'accuracies' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(accuracies.keys(), accuracies.values())\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Comparison: Accuracy Scores')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
